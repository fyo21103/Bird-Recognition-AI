{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"id":"YF6XwLB1U6MF"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import torchvision.transforms as transforms\n","\n","import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import json"]},{"cell_type":"markdown","metadata":{"id":"TVWTkUryVF2X"},"source":["Defining the model"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"0GhGO_sPrkiA"},"outputs":[],"source":["def conv_block(in_channels, out_channels, activation=False, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), nn.BatchNorm2d(out_channels)]\n","    if activation: layers.append(nn.ReLU(inplace=True))\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","class ResNet34(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","        \n","        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=7, stride=1, padding=4), nn.BatchNorm2d(64),nn.MaxPool2d(2), nn.ReLU(inplace=True))\n","        self.res1 = nn.Sequential(conv_block(64, 64,activation=True), conv_block(64, 64))\n","        self.res2 = nn.Sequential(conv_block(64, 64,activation=True), conv_block(64, 64))\n","        self.res3 = nn.Sequential(conv_block(64, 64,activation=True), conv_block(64, 64))\n","        self.downsample1=nn.Sequential(conv_block(64, 128,pool=True)) \n","        self.res4 = nn.Sequential(conv_block(64, 128,activation=True, pool=True), conv_block(128,128))\n","        self.res5 = nn.Sequential(conv_block(128, 128,activation=True), conv_block(128, 128))\n","        self.res6 = nn.Sequential(conv_block(128, 128,activation=True), conv_block(128, 128))\n","        self.res7 = nn.Sequential(conv_block(128, 128,activation=True), conv_block(128, 128))\n","        self.res8 = nn.Sequential(conv_block(128, 256,activation=True, pool=True), conv_block(256,256))\n","        self.downsample2 = nn.Sequential(conv_block(128, 256,pool=True))\n","        self.res9 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n","        self.res10 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n","        self.res11 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n","        self.res12 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n","        self.res13 = nn.Sequential(conv_block(256, 256,activation=True), conv_block(256, 256))\n","        self.res14 = nn.Sequential(conv_block(256, 512,activation=True, pool=True), conv_block(512,512))\n","        \n","        self.downsample3 = nn.Sequential(conv_block(256, 512,pool=True))\n","        self.res15 = nn.Sequential(conv_block(512, 512,activation=True), conv_block(512, 512))\n","        self.res16 = nn.Sequential(conv_block(512, 512,activation=True), conv_block(512, 512,activation=True))\n","\n","        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d((1,1)), nn.Flatten(), nn.Dropout(0.17), nn.Linear(512, num_classes))\n","        \n","    def forward(self, xb):\n","        out = self.conv1(xb)\n","        out = self.res1(out) + out\n","        out = self.res2(out) + out\n","        out = self.res3(out) + out\n","        out = self.downsample1(out) +self.res4(out)\n","        out = self.res5(out) + out\n","        out = self.res6(out) + out\n","        out = self.res7(out) + out\n","        out = self.downsample2(out) +self.res8(out)\n","        out = self.res9(out) + out\n","        out = self.res10(out) + out\n","        out = self.res11(out) + out\n","        out = self.res12(out) + out\n","        out = self.res13(out) + out\n","        out = self.downsample3(out) + self.res14(out) \n","        out = self.res15(out) + out\n","        out = self.res16(out) + out\n","        out = self.classifier(out)\n","        return (out)"]},{"cell_type":"markdown","metadata":{"id":"yQITc0mSVLwm"},"source":["Making list of the classes"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"UnKkUiCYVCOB"},"outputs":[],"source":["# Read JSON file and convert to Python object\n","with open('bird_map.json', 'r') as json_file:\n","    bird_name_map = json.load(json_file)"]},{"cell_type":"markdown","metadata":{"id":"Jr2gWHb5zmla"},"source":["Choosing the device for the model"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"HNFdR0E6VCQM"},"outputs":[],"source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1675020977057,"user":{"displayName":"Modassir Afzal","userId":"04115856496195015671"},"user_tz":-330},"id":"STwGA8aeVCSO","outputId":"f238e011-1ac4-458f-bf2f-53a44013da0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device=get_default_device()\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"CfsMnVYerV4f"},"source":["Loading the model"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"AE92jbXoqmR3"},"outputs":[],"source":["class BirdResnet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Using the pretrained model\n","        self.network = model\n","    \n","    def forward(self, xb):\n","        return (self.network(xb))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1675020980023,"user":{"displayName":"Modassir Afzal","userId":"04115856496195015671"},"user_tz":-330},"id":"4I25rnGRVCUl","outputId":"cbdb9dd7-41fb-42db-94d8-5d9ebc9e208b"},"outputs":[],"source":["# Get the current working directory\n","current_directory = os.getcwd()\n","\n","# Construct the path to your file\n","file_path = os.path.join(current_directory, 'trained-models', 'bird-resnet34best.pth')\n","\n","# Load the entire model\n","model = torch.load(file_path, map_location=device)\n","# No need to call load_state_dict since you're loading the full model\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"d_kerhf8VCW9"},"outputs":[],"source":["stats = ((0.4758, 0.4685, 0.3870), (0.2376, 0.2282, 0.2475))\n","def predict_image(path, model):\n","    im=Image.open(path)\n","    # resizing images then converting image to tensor, normalizing the tensors\n","    transform = transforms.Compose([transforms.Resize((250,250)), transforms.ToTensor(), transforms.Normalize(*stats,inplace=True)]) \n","    img=transform(im)\n","    # Convert to a batch of 1\n","    xb = to_device(img.unsqueeze(0), device)\n","    # Get predictions from model\n","    model.eval()\n","    with torch.no_grad():\n","        yb = model(xb)\n","    # Pick index with highest probability\n","    prob=nn.Softmax(dim=1)\n","    yb=prob(yb)\n","    _, preds  = torch.max(yb, dim=1)\n","    # Retrieve the class label\n","    print('Predicted:', bird_name_map.get(str(preds[0].item())), 'with a probability of', str(round(torch.max(yb).item(), 4)*100)+'%')\n","    #plt.imshow(im)\n","    #plt.show()"]},{"cell_type":"markdown","metadata":{"id":"sG_SKRQuwBkZ"},"source":["Prediction of single images"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"elapsed":94758,"status":"ok","timestamp":1675021082746,"user":{"displayName":"Modassir Afzal","userId":"04115856496195015671"},"user_tz":-330},"id":"dKtvnN30VCZg","outputId":"bb27632b-51c4-4d12-f097-b239d09cd8f1"},"outputs":[{"ename":"AttributeError","evalue":"'collections.OrderedDict' object has no attribute 'eval'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# enter the path of the folder containing the images\u001b[39;00m\n\u001b[0;32m      2\u001b[0m current_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m----> 4\u001b[0m predict_image(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaube.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m), model)\n","Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36mpredict_image\u001b[1;34m(path, model)\u001b[0m\n\u001b[0;32m      8\u001b[0m xb \u001b[38;5;241m=\u001b[39m to_device(img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), device)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Get predictions from model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     12\u001b[0m     yb \u001b[38;5;241m=\u001b[39m model(xb)\n","\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"]}],"source":["# enter the path of the folder containing the images\n","current_directory = os.getcwd()\n","\n","predict_image(os.path.join(current_directory, 'test-data', 'taube.jpg'), model)\n","\n","# predict_image(os.path.join(current_directory, 'test-data', 'taube.jpg'), model)"]},{"cell_type":"markdown","metadata":{"id":"iZ5WRyW5wE0U"},"source":["Prediction of images in a folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":232357,"status":"ok","timestamp":1675021315097,"user":{"displayName":"Modassir Afzal","userId":"04115856496195015671"},"user_tz":-330},"id":"vHxwKiE3Zdco","outputId":"3992c22f-aac7-4f01-cd96-d64d21048113"},"outputs":[],"source":["# enter the path of the folder containing the images\n","current_directory = os.getcwd()\n","\n","# Construct the path to your file\n","path = os.path.join(current_directory, 'trained-models')\n","\n","\n","for file in os.listdir(path):\n","\n","  if file.endswith('jpg') or file.endswith('png') or file.endswith('webp') or file.endswith('jpeg'):\n","\n","    predict_image('/content/'+file, model)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOyrkp0zs80hVcVGHYZMCbn","mount_file_id":"1lAmsYvGA96AIJUcIJ7f_-UZkzcZCc3LV","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
